# Pull in the standard community nginx release
- type: replace
  path: /releases/-
  value:
    name: nginx
    url: https://github.com/cloudfoundry-community/nginx-release/releases/download/v1.12.2/nginx-1.12.2.tgz
    version: 1.12.2
    sha1: e5e5f54d46e2a70fac85ba16e96ccb7e4148bdfa

# Pull nginx-tlsconfig
- type: replace
  path: /releases/-
  value:
    name: nginx-tlsconfig
    url: https://github.com/govau/nginx-tlsconfig-release/releases/download/v3.0.0/nginx-tlsconfig-3.0.0.tgz
    version: 3.0.0
    sha1: dfcd1c665de87df97853b4699b709259dfac5a14

# Pull in latest version of CredHub for our instance
- type: replace
  path: /releases/-
  value:
    name: credhub
    url: https://bosh.io/d/github.com/pivotal-cf/credhub-release?v=1.6.1
    version: 1.6.1
    sha1: 5b3a4ff2cd51d6167bc53eeb8abd47b292e2186f

# Create MySQL database for CredHub
- type: replace
  path: /instance_groups/name=singleton-database/jobs/name=mysql/properties/cf_mysql/mysql/seeded_databases/-
  value:
    name: tlscredhub
    username: tlscredhub
    password: ((tlscredhub_database_password))

- type: replace
  path: /variables/-
  value:
    name: tlscredhub_database_password
    type: password

# ACME Key
- type: replace
  path: /variables/-
  value:
    name: acme_key
    type: rsa

- type: replace
  path: /variables/-
  value:
    name: acme_staging_key
    type: rsa

# Instantiate CredHub instance
- type: replace
  path: /instance_groups/-
  value:
    name: tls-credhub
    instances: 1
    vm_type: minimal
    azs: [z1]
    stemcell: default
    networks:
    - name: default
    jobs:
    - name: consul_agent
      release: consul
      consumes:
        consul_common: {from: consul_common_link}
        consul_server: nil
        consul_client: {from: consul_client_link}
      properties:
        consul:
          agent:
            services:
              credhub:
                name: tls-credhub
                check: {} # TODO, healthcheck
              le-responder:
                name: le-responder
                check: {} # TODO, healthcheck
    - name: le-responder
      release: nginx-tlsconfig
      properties:
        config:
          sources:
            self-signed:
              type: self-signed
            le-prod:
              type: acme
              private_key: ((acme_key.private_key))
              url: https://acme-v01.api.letsencrypt.org/directory
              email: ((certs_le_contact_email))
            le-staging:
              type: acme
              private_key: ((acme_staging_key.private_key))
              url: https://acme-staging.api.letsencrypt.org/directory
              email: ((certs_le_contact_email))

          daemon:
            bootstrap:
              source: self-signed
            days_before: 30
            period: 86400

          data:
            credhub:
              uaa_url: https://uaa.service.cf.internal:8443
              uaa_ca_certificates:
              - ((uaa_ca.certificate))
              client_id: le_responder
              client_secret: ((le_responder_client_secret))
              credhub_url: https://tls-credhub.service.cf.internal:8844
              credhub_ca_certificates:
              - ((tls_credhub_ca.certificate))

          servers:
            acme_responder:
              port: 8478

            admin_ui:
              port: 8427
              uaa:
                client_id: le-responder-user-client
                client_secret: ((le-responder-user-client-secret))
                internal_url: https://uaa.service.cf.internal:8443
                external_url: https://uaa.((system_domain))
                ca_certs:
                - ((uaa_ca.certificate))
              csrf_key: ((le-responder-csrf-key))
              external_url: https://((certs_le_external_domain))
              allowed_users:
              - admin

            nginx_config:
              port: 23352
              clients:
                names:
                - router.service.cf.internal
                ca_certificates:
                - ((tls_credhub_ca.certificate))
              certificate: ((tls_credhub_server))
              hostname: le-responder.service.cf.internal
              template:
                global: |
                  worker_processes 1;
                  error_log  /var/vcap/sys/log/nginx/error.log info;
                events: |
                  worker_connections 1024;
                acme: |
                  location /.well-known/acme-challenge {
                    proxy_pass http://IP_ADDR:8478;
                  }
                http: |
                  # ACME will be inserted before this, if server is resolvable
                  listen 8342;

                  # All other URIs should result in a 301 redirect to equivalent HTTPS pages.
                  location / {
                    return 301 https://$host$request_uri;
                  }
                common: |
                  # this section is always added
                  # server_name, ssl_certificate, ssl_certificate_key are added automatically
                  listen 8452 ssl;
                server:
                  user: |
                    location / {
                      proxy_pass http://127.0.0.1:80;
                      proxy_set_header Host $host;
                    }
                  admin: |
                    access_log /var/vcap/sys/log/nginx/access.log combined;

                    # Will be inserted into admin server block
                    location / {
                      # need as our cookie are a bit big
                      proxy_buffer_size   128k;
                      proxy_buffers   4 256k;
                      proxy_busy_buffers_size   256k;

                      proxy_pass http://IP_ADDR:8427;
                    }

    - name: credhub
      release: credhub
      properties:
        credhub:
          port: 8844
          tls: ((tls_credhub_tls_cert))
          authentication:
            uaa:
              url: https://uaa.service.cf.internal:8443
              verification_key: ((uaa_jwt_signing_key.public_key))
              ca_certs:
              - ((uaa_ca.certificate))
          authorization:
            acls:
              enabled: true
          data_storage:
            type: mysql
            username: tlscredhub
            password: ((tlscredhub_database_password))
            host: sql-db.service.cf.internal
            port: 3306
            database: tlscredhub
            require_tls: false # cf default MySQL doesn't appear to be configured for TLS
          encryption:
            keys:
            - provider_name: int
              encryption_password: ((credhub_encryption_password))
              active: true
            providers:
            - name: int
              type: internal

- type: replace
  path: /variables/-
  value:
    name: credhub_encryption_password
    type: password
    options:
      length: 40

- type: replace
  path: /variables/-
  value:
    name: le-responder-csrf-key
    type: password
    options:
      length: 40

- type: replace
  path: /variables/-
  value:
    name: tls_credhub_ca
    type: certificate
    options:
      is_ca: true
      common_name: tls-credhub-ca.service.cf.internal

- type: replace
  path: /variables/-
  value:
    name: tls_credhub_tls_cert
    type: certificate
    options:
      ca: tls_credhub_ca
      common_name: tls-credhub.service.cf.internal

- type: replace
  path: /instance_groups/name=uaa/jobs/name=uaa/properties/uaa/clients/le-responder-user-client?
  value:
    scope: openid
    authorized-grant-types: authorization_code,refresh_token
    secret: ((le-responder-user-client-secret))
    access_token_validity: 3600
    redirect-uri: https://((certs_le_external_domain))/oauth2callback

- type: replace
  path: /variables/-
  value:
    name: le-responder-user-client-secret
    type: password
    options:
      length: 40

# Create UAA client for le_responder so that it can authenticate to our CredHub
- type: replace
  path: /instance_groups/name=uaa/jobs/name=uaa/properties/uaa/clients/le_responder?
  value:
    authorities: credhub.read,credhub.write
    authorized-grant-types: client_credentials
    secret: "((le_responder_client_secret))"

- type: replace
  path: /variables/-
  value:
    name: le_responder_client_secret
    type: password
    options:
      length: 40

# Create our co-located jobs in the router

# This job generate nginx config from data that is in the CredHub
# During pre-start it will always create a file or error out.
# However it will ignore errors related to being unable to communicate with CredHub,
# and instead generates an empty but valid file (otherwise the rest of the cluster may not start)
# Since the nginx file won't listen on the ports needed, it should ignored by the ELB in front.
# Normally if it encounters an error, it simply won't rewrite the conf.
- type: replace
  path: /instance_groups/name=router/jobs/-
  value:
    name: gen-nginx-config
    release: nginx-tlsconfig
    properties:
      config:
        nginx_pid: /var/vcap/sys/run/nginx/nginx.pid
        config_dir: /var/vcap/data/gen-nginx-config
        server:
          url: https://le-responder.service.cf.internal:23352/nginx
          client_certificate: ((tls_credhub_client))
          ca_certificates:
          - ((tls_credhub_ca.certificate))
        period: 60
        bootstrap: |
          worker_processes 1;
          error_log  /var/vcap/sys/log/nginx/error.log info;
          events {
            worker_connections 1024;
          }

- type: replace
  path: /variables/-
  value:
    name: tls_credhub_client
    type: certificate
    options:
      ca: tls_credhub_ca
      common_name: router.service.cf.internal
      extended_key_usage:
      - client_auth

- type: replace
  path: /variables/-
  value:
    name: tls_credhub_server
    type: certificate
    options:
      ca: tls_credhub_ca
      common_name: le-responder.service.cf.internal
      extended_key_usage:
      - server_auth

# Add a standard nginx, where config is delegated to that produced by the gen-nginx-config job
- type: replace
  path: /instance_groups/name=router/jobs/-
  value:
    name: nginx
    release: nginx
    properties:
      pre_start: |
        #!/bin/bash

        set -x

        NGINX_LOG_DIR=/var/vcap/sys/log/nginx
        NGINX_WORKER=nobody

        mkdir -p "${NGINX_LOG_DIR}"
        chmod -R 0700 "${NGINX_LOG_DIR}"
        chown -R "${NGINX_WORKER}" "${NGINX_LOG_DIR}"

      nginx_conf: |
        include /var/vcap/data/gen-nginx-config/nginx.conf;
